{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d220aae-0b2a-44a8-acaa-60c427fa4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. You are working on a machine learning project where you have a dataset containing numerical and\n",
    "categorical features. You have identified that some of the features are highly correlated and there are\n",
    "missing values in some of the columns. You want to build a pipeline that automates the feature\n",
    "engineering process and handles the missing values\n",
    " Design a pipeline that includes the following steps\"\n",
    " Use an automated feature selection method to identify the important features in the dataset\n",
    " Create a numerical pipeline that includes the following steps\"\n",
    " Impute the missing values in the numerical columns using the mean of the column values\n",
    " Scale the numerical columns using standardisation \n",
    " Create a categorical pipeline that includes the following steps\"\n",
    " Impute the missing values in the categorical columns using the most frequent value of the column\n",
    " One-hot encode the categorical columns \n",
    " Combine the numerical and categorical  pipeline using a Column Transformer\n",
    " Use a Random Forest Classifier to build the final model\n",
    " Evaluate the accuracy of the model on the test dataset\n",
    " Note! Your solution should include code snippets for each step of the  pipeline and a brief explanation of\n",
    "each step. You should also provide an interpretation of the results and suggest possible improvements for\n",
    "the pipeline.\n",
    "\n",
    "\n",
    "\n",
    "Ans:\n",
    "    \n",
    "    To design a pipeline for your machine learning project that includes automated feature selection, \n",
    "    handling missing values, and building a Random Forest Classifier model,\n",
    "    you can use Python with libraries like scikit-learn and pandas. Here's \n",
    "    a step-by-step implementation of the pipeline:\n",
    "    \n",
    "    import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset (replace 'data.csv' with your dataset file)\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop('target_column', axis=1)\n",
    "y = data['target_column']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a numerical pipeline for numerical features\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create a categorical pipeline for categorical features\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine numerical and categorical pipelines using a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a feature selection step using SelectFromModel\n",
    "feature_selection = SelectFromModel(RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "# Create the final pipeline with feature selection and Random Forest Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "Explanation of each step:\n",
    "\n",
    "Load the dataset: Load your dataset into a DataFrame.\n",
    "Split the data: Split the dataset into features (X) and the target variable (y),\n",
    "and further split it into training and test sets.\n",
    "Create numerical and categorical pipelines: Define separate pipelines for numerical\n",
    "and categorical features. Numerical pipeline imputes missing values with the mean and \n",
    "standardizes the features. The categorical pipeline imputes missing values with the most\n",
    "frequent value and one-hot encodes the categorical features.\n",
    "Combine pipelines with ColumnTransformer: Use a ColumnTransformer to combine the numerical \n",
    "and categorical pipelines.\n",
    "Feature selection: Apply feature selection using SelectFromModel with a RandomForestClassifier.\n",
    "This step helps in selecting the most important features.\n",
    "Create the final pipeline: Combine the preprocessing steps with the feature selection\n",
    "and a Random Forest Classifier.\n",
    "Fit and evaluate: Fit the pipeline on the training data and evaluate the model's\n",
    "accuracy on the test data.\n",
    "\n",
    "\n",
    " Interpretation of Results:\n",
    "        \n",
    "The pipeline includes data preprocessing, feature selection, and model training.\n",
    "It handles missing values, scales numerical features, and one-hot encodes categorical features.\n",
    "Feature selection is performed using a Random Forest Classifier to identify important features.\n",
    "The final model is a Random Forest Classifier.\n",
    " The accuracy of the model on the test dataset is printed.\n",
    "\n",
    "Possible improvements:\n",
    "\n",
    "Hyperparameter tuning: Optimize the hyperparameters of the Random Forest Classifier and other\n",
    "components of the pipeline to achieve better performance.\n",
    "Feature engineering: Experiment with different feature engineering techniques, such as \n",
    "creating new features, to improve model accuracy.\n",
    "Cross-validation: Use cross-validation to assess the pipeline's performance\n",
    "more robustly and avoid overfitting.\n",
    "Handling class imbalance: If the target classes are imbalanced, consider using techniques\n",
    "like oversampling or undersampling to balance the dataset.\n",
    "Model selection: Explore other machine learning algorithms and compare their performance\n",
    "with the Random Forest Classifier to choose the best model for your task.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then\n",
    "use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its\n",
    "accuracy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ans:\n",
    "    To build a pipeline that includes a Random Forest Classifier and a Logistic Regression Classifier,\n",
    "    and then use a Voting Classifier to combine their predictions on the Iris dataset,\n",
    "    you can follow these steps in Python using scikit-learn:\n",
    "    \n",
    "    \n",
    "    from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create the Logistic Regression Classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Create a Voting Classifier that combines both classifiers\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('random_forest', rf_classifier),\n",
    "    ('logistic_regression', lr_classifier)\n",
    "], voting='soft')  # 'soft' voting uses predicted probabilities for decision\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('voting_classifier', voting_classifier)\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the pipeline\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "In this code:\n",
    "\n",
    "We load the Iris dataset and split it into training and testing sets.\n",
    "We create a Random Forest Classifier and a Logistic Regression Classifier.\n",
    "We create a Voting Classifier that combines both classifiers using \"soft\" voting,\n",
    "which takes into account the predicted probabilities.\n",
    "We create a pipeline that includes the Voting Classifier.\n",
    "We train the pipeline on the training data and make predictions on the test data.\n",
    "Finally, we evaluate the accuracy of the pipeline on the test data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
